{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영문 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('i love you', 'pos'),('i hate you', 'neg'),('you like me', 'neg'),('i like her','pos')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 문 이해하기\n",
    "\n",
    "- 일단, train 안에 있는 것을 sentence ---> for sentence in train\n",
    "- setence 안에 있는 것을 word라고 하는 데, word는 sentence 0번의 토큰화 한것 ----> for word in word_tokenize(setence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate', 'her', 'i', 'like', 'love', 'me', 'you'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(word for sentence in train for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 문장에 단어가 속해있는지 파악하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'i': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'like': False,\n",
       "   'you': True,\n",
       "   'love': True,\n",
       "   'hate': False},\n",
       "  'pos'),\n",
       " ({'i': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'like': False,\n",
       "   'you': True,\n",
       "   'love': False,\n",
       "   'hate': True},\n",
       "  'neg'),\n",
       " ({'i': False,\n",
       "   'me': True,\n",
       "   'her': False,\n",
       "   'like': True,\n",
       "   'you': True,\n",
       "   'love': False,\n",
       "   'hate': False},\n",
       "  'neg'),\n",
       " ({'i': True,\n",
       "   'me': False,\n",
       "   'her': True,\n",
       "   'like': True,\n",
       "   'you': False,\n",
       "   'love': False,\n",
       "   'hate': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(sentence[0])) for word in all_words}, sentence[1]) for sentence in train]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train 문자에 붙은 긍정, 부정 태그를 이용해 분류한 결과== 'hate'라는 단어가 없을 때(false) 긍정일 비율이 1.7 : 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                    love = False             neg : pos    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n",
      "                    like = False             neg : pos    =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "c = nltk. NaiveBayesClassifier.train(t)\n",
    "c.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test 는 딕셔너리 형태야\n",
    "- word 는 test_sentence를 토큰화한 것 인데, 그게 all_words에 있는지 없는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': True,\n",
       " 'me': False,\n",
       " 'her': False,\n",
       " 'like': True,\n",
       " 'you': False,\n",
       " 'love': False,\n",
       " 'hate': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'i like soobin'\n",
    "test = {word : (word in word_tokenize(test_sentence)) for word in all_words }\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.classify(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love happy weekend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bore work job</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bore weekend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy together</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mail  label\n",
       "0          i love you      1\n",
       "1  love happy weekend      1\n",
       "2       bore work job      0\n",
       "3          i hate you      0\n",
       "4        bore weekend      0\n",
       "5      happy together      1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('C:/Users/LG/00.sb/naivebayes_example.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love you', 'love happy weekend', 'bore work job', 'i hate you', 'bore weekend', 'happy together']\n",
      "[1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "x_train = list(df['mail'])\n",
    "y_train = list(df['label'])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- token 화 하는 방법\n",
    "- 중복을 제거하는 방법== set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'together', 'i', 'job', 'you', 'happy', 'work', 'love', 'hate', 'weekend', 'bore'}\n"
     ]
    }
   ],
   "source": [
    "all_words = set([word for sentence in x_train for word in word_tokenize(sentence)])\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'i': True,\n",
       "   'love': True,\n",
       "   'you': True,\n",
       "   'happy': False,\n",
       "   'weekend': False,\n",
       "   'bore': False,\n",
       "   'work': False,\n",
       "   'job': False,\n",
       "   'hate': False,\n",
       "   'together': False},\n",
       "  [1, 1, 0, 0, 0, 1]),\n",
       " ({'i': False,\n",
       "   'love': True,\n",
       "   'you': False,\n",
       "   'happy': True,\n",
       "   'weekend': True,\n",
       "   'bore': False,\n",
       "   'work': False,\n",
       "   'job': False,\n",
       "   'hate': False,\n",
       "   'together': False},\n",
       "  [1, 1, 0, 0, 0, 1]),\n",
       " ({'i': False,\n",
       "   'love': False,\n",
       "   'you': False,\n",
       "   'happy': False,\n",
       "   'weekend': False,\n",
       "   'bore': True,\n",
       "   'work': True,\n",
       "   'job': True,\n",
       "   'hate': False,\n",
       "   'together': False},\n",
       "  [1, 1, 0, 0, 0, 1]),\n",
       " ({'i': True,\n",
       "   'love': False,\n",
       "   'you': True,\n",
       "   'happy': False,\n",
       "   'weekend': False,\n",
       "   'bore': False,\n",
       "   'work': False,\n",
       "   'job': False,\n",
       "   'hate': True,\n",
       "   'together': False},\n",
       "  [1, 1, 0, 0, 0, 1]),\n",
       " ({'i': False,\n",
       "   'love': False,\n",
       "   'you': False,\n",
       "   'happy': False,\n",
       "   'weekend': True,\n",
       "   'bore': True,\n",
       "   'work': False,\n",
       "   'job': False,\n",
       "   'hate': False,\n",
       "   'together': False},\n",
       "  [1, 1, 0, 0, 0, 1]),\n",
       " ({'i': False,\n",
       "   'love': False,\n",
       "   'you': False,\n",
       "   'happy': True,\n",
       "   'weekend': False,\n",
       "   'bore': False,\n",
       "   'work': False,\n",
       "   'job': False,\n",
       "   'hate': False,\n",
       "   'together': True},\n",
       "  [1, 1, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= [({word : (word in word_tokenize(sentence)) for word in all_words}, y_train) for sentence in x_train]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('메리가 좋아','pos'),('고양이도 좋아','pos'),('난 수업이 지루해','neg'),('메리는 이쁜 고양이야','pos'),('난 마치고 메리랑 놀거야','pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'지루해', '난', '메리는', '이쁜', '마치고', '좋아', '수업이', '고양이야', '고양이도', '놀거야', '메리랑', '메리가'}\n"
     ]
    }
   ],
   "source": [
    "all_words = set(word for sentence in train for word in word_tokenize(sentence[0]))\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [({word : (word in word_tokenize(sentence[0])) for word in all_words}, sentence[1]) for sentence in train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                    고양이도 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     놀거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리가 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리는 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리랑 = False             neg : pos    =      1.1 : 1.0\n",
      "                      이쁜 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "c= nltk.NaiveBayesClassifier.train(t)\n",
    "c.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'지루해': False,\n",
       " '난': True,\n",
       " '메리는': False,\n",
       " '이쁜': False,\n",
       " '마치고': False,\n",
       " '좋아': False,\n",
       " '수업이': False,\n",
       " '고양이야': False,\n",
       " '고양이도': False,\n",
       " '놀거야': True,\n",
       " '메리랑': True,\n",
       " '메리가': False}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '난 수업을 마치면 메리랑 놀거야'\n",
    "\n",
    "test_sent = {word : (word in word_tokenize(test)) for word in all_words}\n",
    "test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
